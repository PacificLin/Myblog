---
author: Pacific
categories:
- Spark
- Python
date: "2021-04-02"
description: 
image: 
tags:
- Spark
- Python
- Pyspark
- Sparksql
title: Window Functions in PySpark
---

## functions in PySpark

ä¸€èˆ¬æˆ‘å·¥ä½œçš„ Spark ç’°å¢ƒï¼Œå¯ä»¥ä½¿ç”¨ Hive | sparklyr | PySpark ä¾†æ“ä½œ Spark dataframeï¼Œé€™ç¯‡ä»¥ PySpark çš„ç’°å¢ƒä¾†ç¤ºç¯„æ“ä½œ window functions ğŸ˜® 

ç”±æ–¼æ˜¯ Spark æ˜¯ä½¿ç”¨åˆ†æ•£é‹ç®—ï¼Œå› æ­¤ Spark çš„ç’°å¢ƒä¸¦ç„¡æ³•ä½¿ç”¨ pandas çš„ module ä¾†è™•ç†è³‡æ–™ï¼Œè€Œä¸€èˆ¬ Spark SQL æ”¯æŒçš„ function åœ¨ PySpark çš„ç’°å¢ƒæœ‰å…©ç¨®

> 1. å…§ç½®å‡½æ•¸æˆ– UDF(user define function)ï¼šé‡å°æ¯ä¸€å€‹ row è¿”å›è¨ˆç®—å¾Œçš„å€¼
>
> 2. èšåˆå‡½æ•¸ï¼šä¾‹å¦‚ sum | count | max ç­‰ç­‰ï¼Œä¾æ“šåˆ†çµ„é€²è¡Œé‹ç®—ï¼Œåˆä½µçµ„å¾Œè¿”å›è¨ˆç®—çš„å€¼

ä½†ä»¥ä¸Šçš„ function ç„¡æ³•æ»¿è¶³æ›´ç‚ºè¤‡é›œçš„é‹ç®—ï¼Œä¾‹å¦‚ç„¡æ³•åŒæ™‚é‡å°ä¸€çµ„é€²è¡Œæ“ä½œï¼Œä¸”é‡å°æ¯ä¸€å€‹ row è¿”å›å…¶ç‰¹å®šçš„å€¼ï¼Œä¸€èˆ¬æˆ‘å€‘ç¨±åšé€™ç¨®è¨ˆç®—ç‚º window function

åœ¨ `Spark 1.4` ä¹‹å¾Œï¼Œæä¾›äº† sql.windows å‡½æ•¸ä¾†è§£æ±ºä»¥ä¸Šçš„å›°æ“¾

```python
from pyspark.sql import Window
```

ä»¥ä¸‹ä¾†è¬›è§£ä½¿ç”¨çš„æ–¹å¼å’Œæ™‚æ©Ÿï¼Œå‡è¨­æˆ‘å€‘æœ‰ä»¥ä¸‹ table å« `temp.wm`

nameï¼šç”¨æˆ¶åå­—

assetsï¼šè³‡ç”¢éƒ¨ä½

valueï¼šè³‡ç”¢åƒ¹å€¼

| name  | assets | value  |
| ----- | ------ | ------ |
| Jason | stock  | 6500   |
| Jason | fund   | 10000  |
| Jason | bond   | 15000  |
| Mike  | fund   | 12000  |
| Mike  | bond   | 350000 |
| Mike  | stock  | 200000 |
| Julia | gold   | 100000 |
| Julia | fund   | 5000   |
| Julia | stock  | 100000 |

æˆ‘å€‘è¦æ‰¾å‡ºæ¯ä¸€å€‹ç”¨æˆ¶æ‰€æ“æœ‰çš„æœ€é«˜å’Œç¬¬äºŒé«˜åƒ¹å€¼çš„è³‡ç”¢é …ç›®ï¼Œä¸€èˆ¬è€Œè¨€ SQL å¯«æ³•å¦‚ä¸‹

```sql
SELECT a.*
FROM 
 (
  SELECT
   name,
   assets,
   value,
   dense_rank() OVER (PARTITION BY name ORDER BY value DESC) AS rank
  FROM temp.wm
 ) AS a
WHERE a.rank < 3	
```

å¦‚æœå°æ–¼åˆ†çµ„å¾Œå€‹åˆ¥è¨ˆç®—çš„ window functions çµ„æˆèªæ³•ä¸ç†Ÿæ‚‰ï¼Œä¸‹é¢ç°¡å–®èªªæ˜

- partitionByï¼šåˆ†çµ„ï¼Œé¸æ“‡åˆ†çµ„çš„æ¬„ä½
- orderByï¼šæ’åºï¼ŒæŒ‰ç…§è©²æ¬„ä½ä¸¦ä¾ç…§ function æ’åº
- dense_rank()ï¼šwindow function çš„ä¸€ç¨®ï¼Œä¾ç…§ ORDER BY æ‰€æŒ‡å®šçš„æ¬„ä½å°æ–¼æ¯å€‹ row è¿”å›å€¼ 1, 2, 3...

ä¹Ÿå¯ä»¥åƒè€ƒä»¥ä¸‹é€£çµçš„æ•™å­¸

[SQL Window Functions | Advanced SQL - Mode Analytics](https://mode.com/sql-tutorial/sql-window-functions/)

å‰‡ç”¢å‡ºçš„çµæœå¦‚ä¸‹

| name  | assets | value  | rank |
| ----- | ------ | ------ | ---- |
| Jason | bond   | 15000  | 1    |
| Jason | fund   | 10000  | 2    |
| Mike  | bond   | 350000 | 1    |
| Mike  | stock  | 200000 | 2    |
| Julia | gold   | 100000 | 1    |
| Julia | stock  | 100000 | 1    |
| Julia | fund   | 5000   | 2    |

è€Œåœ¨ Spark è£¡å¦‚æœä¸ä½¿ç”¨ window functions è™•ç†ï¼Œä¹Ÿç„¡æ³•ä½¿ç”¨ pandas çš„æƒ…æ³ä¸‹è™•ç† data å°±æœƒç›¸å°è¤‡é›œä¸”ä¸æ˜“è®€ï¼Œæ•…ä»¥ä¸‹å‰‡ä»¥ Pysaprk é€é window function ä¾†ç¤ºç¯„è™•ç†

```python
import sys
from pyspark.sql.window import Window
import pyspark.sql.functions as F
df = sqlContext.table("temp.wm")

window_spec = Window.partitionBy("name") \
	.orderBy(F.col("value").desc())
    
df2 = df.withColumn("rank", Window.rank().over(window_spec)) \
	.filter(df.rank < 3).show(6, truncate = False)
```

ä»¥ä¸‹å‰‡æ˜¯ PySpark æœ‰æ”¯æ´çš„ window functions åˆ—è¡¨ï¼Œä»¥åŠå’Œ SQL çš„å°ç…§

### window functions åˆ—è¡¨

|                        | SQL                       | DataFrame API |
| ---------------------- | ------------------------- | ------------- |
| **Ranking functions**  | rank                      | rank          |
|                        | dense_rank                | denseRank     |
|                        | percent_rank              | percentRank   |
|                        | ntile                     | ntile         |
|                        | row_number                | rowNumber     |
| **Analytic functions** | cume_dist                 | cume_dist     |
|                        | first_value               | firstValue    |
|                        | last_value                | lastValue     |
|                        | lag(Column, offset: Int)  | lag           |
|                        | lead(column, offset: Int) | lead          |

ä»¥ä¸‹é‡å°æœ€å¸¸ææ··çš„çš„å¹¾å€‹ functions åšèªªæ˜ï¼Œä¸¦ä»¥ temp_wm è£¡çš„ç”¨æˆ¶ Julia åšèªªæ˜

* `row_number()`

å¾ 1 é–‹å§‹ï¼Œæ ¹æ“š ORDER BY æ‰€æŒ‡å®šçš„ column åšæ’åº

| name  | assets | value  | row_number() |
| ----- | ------ | ------ | ------------ |
| Julia | gold   | 100000 | 1            |
| Julia | stock  | 100000 | 2            |
| Julia | fund   | 5000   | 3            |

* `rank()`

å¾ 1 é–‹å§‹ï¼Œæ ¹æ“š ORDER BY æ‰€æŒ‡å®šçš„ column åšæ’åº

| name  | assets | value  | rank() |
| ----- | ------ | ------ | ------ |
| Julia | gold   | 100000 | 1      |
| Julia | stock  | 100000 | 1      |
| Julia | fund   | 5000   | 3      |

> rank å’Œ row_number çš„å·®ç•°åœ¨æ–¼å¦‚æœ column çš„å€¼ç›¸åŒï¼Œ row_number ä¸¦ä¸æœƒé‡è¤‡çµ¦å€¼ï¼ˆï¼‘, 2, 3ï¼‰ï¼Œä½† rank å‰‡æœƒï¼ˆ1, 1, 3ï¼‰

* `dense_rank()`

å¾ 1 é–‹å§‹ï¼Œæ ¹æ“š ORDER BY æ‰€æŒ‡å®šçš„ column åšæ’åº

| name  | assets | value  | dense_rank() |
| ----- | ------ | ------ | ------------ |
| Julia | gold   | 100000 | 1            |
| Julia | stock  | 100000 | 1            |
| Julia | fund   | 5000   | 2            |

> rank å’Œ dense_rank çš„å·®ç•°åœ¨æ–¼å¦‚æœ column çš„å€¼ç›¸åŒï¼Œ rank æœƒè·³éè¢«é‡è¤‡çš„å€¼æ‰€ä½”æ“šçš„ä½å­ï¼ˆï¼‘, 1, 3ï¼‰ï¼Œä½† dense_rank å‰‡ä¸æœƒï¼ˆ1, 1, 2ï¼‰

ä»¥ä¸‹å†ç¤ºç¯„ç¨å¾®è¤‡é›œçš„ä½œæ³•ï¼Œå¦‚æœæˆ‘å€‘æƒ³çŸ¥é“æ¯å€‹äººçš„è³‡ç”¢åƒ¹å€¼èˆ‡å…¶æ“æœ‰æœ€é«˜åƒ¹å€¼çš„è³‡ç”¢ç›¸å·®å¤šå°‘

```python
import sys
from pyspark.sql.window import Window
import pyspark.sql.functions as F
df = sqlContext.table("temp.wm")

window_spec = Window.partitionBy("name") \
	.orderBy(F.col("value").desc())

df2 = df.withColumn("max_value", Window.max("value").over(window_spec)) \
    .withColumn("value_diff", F.col("max_value") - F.col("value")) \ 
    .selct("name", "assets", "value", "value_diff").show(9, truncate = False)
```

åˆ©ç”¨ window function è¨ˆç®—å‡ºæ¯å€‹ç”¨æˆ¶çš„æœ€å¤§è³‡ç”¢åƒ¹å€¼ï¼Œå†èˆ‡å…¶æ¯å€‹è³‡ç”¢é …ç›®åšç›¸æ¸› â€‹â€‹

å¦‚æœæ²’æœ‰ä½¿ç”¨ window functionsï¼Œå‰‡éœ€è¦é€é aggregation å‡½æ•¸è¨ˆç®—å‡ºæ¯å€‹ç”¨æˆ¶çš„è³‡ç”¢æœ€å¤§å€¼ï¼Œå†é€é join åˆä½µ dataframe å†è¨ˆç®—ä¹‹ï¼Œå› æ­¤ window functions ç›¸å°çš„ç°¡æ½”ä¸”æ˜“è®€

æœ€å¾Œçµæœå¦‚ä¸‹ ğŸ™„ 

| name  | assets | value  | value_diff |
| ----- | ------ | ------ | ---------- |
| Jason | bond   | 15000  | 0          |
| Jason | fund   | 10000  | 5000       |
| Jason | stock  | 6500   | 8500       |
| Mike  | bond   | 350000 | 0          |
| Mike  | stock  | 200000 | 150000     |
| Mike  | fund   | 12000  | 338000     |
| Julia | gold   | 100000 | 0          |
| Julia | stock  | 100000 | 0          |
| Julia | fund   | 5000   | 95000      |

### ROW FRAME æ™‚é–“çª—å£

- `partitionBy`ï¼šåˆ†çµ„ï¼Œæ‰€æœ‰çš„é€šé rowsBetween å’Œ rangeBetween åˆ‡å‰²å‡ºä¾†çš„å¹€éƒ½æ˜¯åœ¨åˆ†çµ„çš„åŸºç¤ä¸Šçš„

- `orderBy`ï¼šæ’åºï¼Œé€™å€‹æ¯”è¼ƒå¥½ç†è§£ï¼Œå°±æ˜¯æŒ‰ç…§é‚£å€‹å­—æ®µæ’åº

- `rowsBetween/rangeBetween` ï¼šrowBetween æ˜¯ç•¶å‰è¡Œçš„å‰æˆ–è€…å¾Œå¹¾è¡Œï¼ŒrangeBetween æ˜¯é‡å° orderby çš„å€¼è¨ˆç®—å‡ºä¾†çš„ç¯„åœå†å’Œ orderby æ¯”è¼ƒä¾†å¾—åˆ°æ™‚é–“å¹€

  * rowsBetween ä¸é—œå¿ƒç¢ºåˆ‡çš„å€¼ã€‚å®ƒåªé—œå¿ƒè¡Œçš„é †åºï¼Œä¸¦ä¸”åœ¨è¨ˆç®—å¹€æ™‚æ¡ç”¨å›ºå®šæ•¸é‡çš„å‰å¾Œè¡Œ
  * rangeBetween è¨ˆç®—æ¡†æ¶æ™‚è€ƒæ…®å€¼

  rowsBetween èªæ³•ç‚º rowsBetween(x, y)ï¼Œå…¶ä¸­ x, y å¯ä»¥æ˜¯æ•¸å­—ï¼Œ-n è¡¨ç¤ºå‘å‰æ•¸ n è¡Œï¼Œnè¡¨ç¤ºå‘å¾Œæ•¸ n è¡Œ

è€Œ rowsBetween/rangeBetween ä¹Ÿå¯ä½¿ç”¨ä»¥ä¸‹æ–¹å¼ä¾†è¡¨ç¤º

- `Window.unboundedPreceding` è¡¨ç¤ºç•¶å‰è¡Œçš„ç„¡é™è¡Œ
- `Window.currentRow` è¡¨ç¤ºç•¶å‰è¡Œ
- `Window.unboundedFollowing` è¡¨ç¤ºç•¶å‰è¡Œä¹‹å¾Œçš„ç„¡é™è¡Œ

åœ¨ä¸€æ¬¡ç”¨ `temp` çš„ table åšèˆ‰ä¾‹ï¼Œä½†æ•¸å­—ç¨å¾®åšèª¿æ•´å¦‚ä¸‹

| name  | assets | value  |
| ----- | ------ | ------ |
| Jason | stock  | 6500   |
| Jason | fund   | 10000  |
| Jason | bond   | 15000  |
| Mike  | fund   | 12000  |
| Mike  | bond   | 350000 |
| Mike  | stock  | 100000 |
| Julia | gold   | 100000 |
| Julia | fund   | 5000   |
| Julia | stock  | 100000 |

`rowsBetween` ä¸­çš„å¹€ä¸ä¾è³´æ–¼ orderBy å­å¥ã€‚æ‰€ä»¥æœƒä¾ç…§åˆ†çµ„å¾Œåšç¨ç«‹è¨ˆç®—

```python
window_spec = Window.partitionBy('assets').orderBy('value').rowsBetween(Window.unboundedPreceding, Window.currentRow)
df.withColumn('RowsBetween', F.sum(df.value).over(window_spec)).show()
```

| name  | assets | value  | RowsBetween |
| ----- | ------ | ------ | ----------- |
| Jason | stock  | 6500   | 6500        |
| Julia | stock  | 100000 | `106500`    |
| Mike  | stock  | 100000 | `206500`    |
| Julia | fund   | 5000   | 5000        |
| Jason | fund   | 10000  | 15000       |
| Mike  | fund   | 12000  | 27000       |
| Jason | bond   | 15000  | 15000       |
| Mike  | bond   | 350000 | 365000      |
| Julia | gold   | 10000  | 10000       |

æ”¹ç”¨ `rangeBetween` ï¼Œå¯ä»¥ç™¼ç¾ç”¢å‡ºçš„å€¼æœƒå–æ±ºæ–¼ orderBy å­å¥ï¼Œå¦‚æœå€¼ç›¸åŒï¼Œæœƒè¨ˆç®—æ‰€æœ‰ç›¸åŒå€¼å¾—æ‰€æœ‰è¡Œï¼Œå› æ­¤ç›¸åŒçš„ value åœ¨åŒä¸€è¡Œæœƒä¸€æ¬¡åšè¨ˆç®—

```
window_spec = Window.partitionBy('assets').orderBy('value').rangeBetween(Window.unboundedPreceding, Window.currentRow)
df.withColumn('RowsBetween', F.sum(df.value).over(window_spec)).show()
```

| name  | assets | value  | RowsBetween |
| ----- | ------ | ------ | ----------- |
| Jason | stock  | 6500   | 6500        |
| Julia | stock  | 100000 | `206500`    |
| Mike  | stock  | 100000 | `206500`    |
| Julia | fund   | 5000   | 5000        |
| Jason | fund   | 10000  | 15000       |
| Mike  | fund   | 12000  | 27000       |
| Jason | bond   | 15000  | 15000       |
| Mike  | bond   | 350000 | 365000      |
| Julia | gold   | 10000  | 10000       |



### åƒè€ƒä¾†æº

[Introducing Window Functions in Spark SQL - The Databricks Blog](https://databricks.com/blog/2015/07/15/introducing-window-functions-in-spark-sql.html)

[SQL Window Functions | Advanced SQL - Mode Analytics](https://mode.com/sql-tutorial/sql-window-functions/)

[PySpark Window Functions â€” SparkByExamples](https://sparkbyexamples.com/pyspark/pyspark-window-functions/)

[SQLé«˜ç´šçŸ¥è­˜â€”â€”OVERé–‹çª—å‡½æ•¸çš„ç”¨æ³• - æ¯æ—¥é ­æ¢ (kknews.cc)](https://kknews.cc/zh-tw/code/66jnqzv.html)